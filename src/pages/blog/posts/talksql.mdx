---
layout: ../../../layouts/PostLayout.astro
title: Creating TalkSQL
subtitle: An AI powered application for converting natural language to SQL
date: "2023, May 15 to Now"
---

import { Icon } from "astro-icon";

It is the year of 2023, and you want to create an application. What is the first thing that comes to mind?

Artificial intelligence.

AI has become the buzz word to attach to whatever you create to get traction.
Just look at the stars on repos of AI toofls.
And I, following the trend, decided to create something with the power of AI.
A fancy way of saying it calls OpenAI's API.

In the following I'll be taking you through the process of creating it,
sharing the problems I encounter, the solutions I find, and what I learn.

## Ideas And Plans

First off, you need to give some shape to the idea you have.

So I decided that TalkSQL will be a desktop application.

> "Why not a webapp?", you ask.

Well, because it'll be able to detect your db schemas.
I'll need to be able to connect to databases on the system.

> "I don't know if you know this, but, uh, pretty much all databases are hosted on the cloud", you remark.

The fact of the matter is, I did not remember that basic fact at the time.
And now I've invested too much time into working with Tauri, and in turn into Rust, to redo it.

Which brings me to my stack. What I'll use to build this glorious app.

- **Tauri**: a Rust framework for building desktop apps using web frontends.
  Mixing the soy with the meat, like no other. You just bring your frontend code, and throw it in there,
  and it'll work better than Electron.

* **Svelte**: a frontend framework which will provide the UI that Tauri will show.
  I picked it because it is simple, fast(er than react), and has builtin transitions, which I'm not good at.
  Needless to say, I'll be using it with Typescript and Tailwind.

- **SQLite**: a local database that will store our data.
  Now, obviously you're not going to be working with it from the frontend,
  you'll have to use it through Rust. I found the **sqlx** package to be a good choice.

* Along with some little tools here and there which are not important,
  but I'll mention that the package (or crates) I used for dealing with OpenAI is **async-openai**.

The idea of this app is that the user, a respectable fella like yourself, can install it,
and enter a database connection for TalkSQL to use to fetch the schema.
Now the user will provide their openai key to TalkSQL, enter a prompt,
and a request will be sent with the full context of the schema.
The user will essentially get a translation and adaptation of the prompt in SQL.

> "Um, this is kind of lame", you interject.

Go again in a bit, please.

A very simple example of this will be:

```sh
# prompt entered
Get the full names of all students.
```

```sql
-- response gotten
GET first_name, last_name FROM students;
```

What were you saying?

> "I think the idea sucks, I can just ask chatgpt."

To start, it is very rude of you to demean my projects in my own blog.
But your point is valid. It isn't really innovative, or cool.
It is just a simple application that will, hopefully, do one task and do it well.

Need to write some SQL but don't want to bother? Spin up TalkSQL and just type it.

I do hope to maximize the efficiency and accuracy of the prompts passed to openai,
so as to make the application better suited for SQL writing rather than a plain ChatGPT.
But that is a task for the end of it all.

Now, I gotta say I personally like to prototype in figma as a start.

If you're that kind of guy, your blood pressure is probably rising right now. I'm sorry.

> "You gotta start with the database schema, you fool!"

I know, but for some projects, I've found it is easier to get a feel of the UI first,
see what the user will see and the flow of the app, and then work on the backend.

> "You're a disgrace to the programming community."

Okay, you're going too far now. Let us see the design I came up with.
This is what I'll be working towards, and I'll be updating it as I go, since this post is written as I go.

<iframe
	height="450"
	style="border-radius: 1rem; margin: 1rem 0;"
	src="https://www.figma.com/embed?embed_host=share&url=https%3A%2F%2Fwww.figma.com%2Ffile%2FxaNnfbb8ThdBkL2Rlz8SNF%2FTalkSQL%3Ftype%3Ddesign%26node-id%3D0%253A1%26t%3DlPEUu7ahUza1eq2Z-1"
	allowfullscreen
></iframe>

I chose purple as the main color because why not.
And as you can see there is two screens and a side menu.
I've also added a little architecture diagram to show parts of the app,
though to be honest it is just a bunch of boxes I drew in figma.

How do you like the design?

> "It's-"

NO! don't say it. Let us just move unto the plan.

## Scafollding And Starting

When starting a new project it is always good to start with a proper structure.
Good projects will provide you with a starter tool. Tauri, being a great project, does, too.
They've even made it into a NPM package, so you can easily run it:

```bash
npx create-tauri-app
```

You'll be asked a bunch of questions, and you'll know how to answer if you know what you're building.
I've explained the stack earlier, so I make my choices accordingly.

Now the project will look like a regular webapp, but with a **src-tauri** directory,
where the files of Rust code make their home.

I need some rust packages, as said eariler. So I go into the directory and install the following packages:

```
cargo add async-openai sqlx dirs
```

In the rust code you'll find a function with a macro on it:

```rust
#[tauri::command]
async fn say_hello() -> {
  "hello".toString()
}
```

Basically, Tauri let's you call these functions from the frontend you'll build.
So these act like backend API endpoints. You can pass these functions arguments,
and have them return their results.

Easy enough, right? Well, not if you don't know how to write rust. I know some, but it is still difficult.

I created two directories, one for services and one for models.

The **models** directory contained files each with the data structure of a table and future CRUD operations on the db:

- aiconfig: Data related to configuration of the AI.
- databases: Databases we're going to connect to and their credentials.
- preferences: data related to the app configuration.
- entries: A group of prompt, sql reply, and explanation. Each belongs to a talk.
- talks: Each talk is connected to one database, and has many entries in it.

While the **services** directory has files each with one functionality that is needed for the app:

- prompt_ai: dealing with the openai API (will be using async-openai here).
- db: dealing with the database connection and migrations (will be using sqlx here).
- schema_reader: reading the schema of the database connections we're given (the only part I'm unsure about, since I've never coded such a thing).
- translation: for asking openai in some unsupported languages (like my native language).

> "Aha! So you admit it now. You gotta do database and backend first."

Yes, I'm not stupid enough to invest weeks into a nice UI and then discover the idea is not feasable.

I've done that too many times! Not again.

But I just like to have a feel for the UI and have something to look at.
Usually takes little time to create in Figma.

I must confess, too. Trying to find a database solution was not easy.
Mostly because I don't know how to work with databases in Rust (there being no global variables).
I decided on a local one, and tried some others.

- sled: A key-value storage. I was afraid it wouldn't fit with application, or that I wouldn't know how to use it.
  I don't think it is a good idea to try learning a bunch of things in one project.

* surrealdb: A document-graph database, tha can be embedded. I still not sure how it can be embedded.
  Again, this DB uses a different paradigm, and I'd have to learn that.

- rusqlite: SQLite binding for Rust. I just couldn't configure it.

Which leads me to my chosen one: **sqlx**, not to be confused with Go's **sqlx**,
will let you write normal SQL and make setup and migrations easy.
I have to thank [this blogpost](https://tms-dev-blog.com/rust-sqlx-basics-with-sqlite) which shows examples of
the basics in using **sqlx** with SQLite. It was quite easy to apply it to the Tauri base.

I'll not be inserting all the code I wrote here, since the project is open-source
and you can check it out for yourself.

> "You really thought I needed a line-by-line walkthrough?"

I mean you could've. How could I possibly know my intended non-existent audience in my first ever blog post?

The logic for the DB setup is as follows: I get the data directory of the system,
write a sqlite file if it does not exist, and connect. Like so:

```rust
let full_path = format!("sqlite://{}", db_path.to_string_lossy());

// if the database does not exist create it
if !db_exists {
	Sqlite::create_database(&full_path).await;
}

// connect to the database
let db_client = SqlitePool::connect(&full_path).await;
```

But we have not discussed migrations yet.

If you don't know how migrations work (you're like me before writing this application),
they're basically steps that must be done to get the database into the state you want.
It is like git for database schemas.

For **sqlx** you have to create a directory named migrations.
So there I put my initial schema, with all tables, as specified in the models section.

You have to create files in the migrations directory using **sqlx**, so installing its CLI is required.

```bash
cargo install sqlx
```

And create like this:

```bash
sqlx migrate add migration_title
```

Now you have to run migrations on app start. So we put the logic in the main function:

```rust
sqlx::migrate!("./migrations")
	.run(&db)
	.await;
```

This will run any migrations in the directory on the database, and bring its state up to date with any changes.

Let us move to setting up the ai. You simply create a client and use that.

```rust
let ai_client = async_openai::Client::new().with_api_key();
```

It gets the api key from the environment variable.
And this might be news to you, as it was to me, in rust you usually don't import environment variables.
They're imported by themselves. You just have to export them from your shell.

```bash
export OPENAI_API_KEY="sk-Iamnotgivingyouafreeapikeydontworry"
```

I added this to **.bashrc** which makes it available even after closing the shell.

To test it out, you gotta do the following. Now, now, don't be intimidated. Don't be like me.

```rust
let request = CreateChatCompletionRequestArgs::default()
	.max_tokens(512u16)
	.model("gpt-3.5-turbo")
	.messages([
		ChatCompletionRequestMessageArgs::default()
			.role(Role::System)
			.content("You are a helpful assistant.")
			.build()
			.expect("could not create message"),
		ChatCompletionRequestMessageArgs::default()
			.role(Role::User)
			.content("Assure me that rust is not complex.")
			.build()
			.expect("could not create message"),
	])
	.build()
	.expect("could not");

let response = state
	.ai
	.chat()
	.create(request)
	.await
	.expect("could not get ai response");
```

Essentially you have to manually create each request you make, then create a chat by using it.
I imageine it'll be tough generating that messages array/vector from user and ai messages later.
I might've done something similar in a Typescript project, but we're doing Rust here.

Alright, the database client is ready, and so is the openai client.
As I said before, in Rust we don't use global variables.

What does this mean, can you guess?

We got to pass every function those clients, if we want them to have access.

Now if you've been writing something that is, well, not Rust, this might sound insane.
Our problems are magnified by the fact that we're using Tauri.
Each handler that we make is a function that will have to receive those values.

But we aren't Columbus here. The developers behind tauri have thought of this.

The solution is to use state.

You create a state and pass it values when starting up the tauri up:

```rust
// the structure of the state
pub struct AppState {
	db: Pool<Sqlite>,
	ai: Client,
}

async fn main(){

  // creating the clients for db and ai here

  // passing the clients to the state
  tauri::Builder::default()
	  .manage(AppState { db, ai })
}
```

And then all handlers will receive the state. The handlers are passed here, by the way:

```rust
tauri::Builder::default()
	.manage(AppState { db, ai })
	// attach handlers to call from frontend
	.invoke_handler(tauri::generate_handler![
    // example handler
    test_ai
  ])
```

The handlers take in state as a parameter:

```rust
#[tauri::command]
pub async fn test_ai(state: State<'_, AppState>) {
  // use state here
}
```

Easy, right? It did not take me a day or two figuring all this out.

Currently, the main aspects of the application are connected and the general structure is laid out.

## Grinding And The Backend

Now we have to add CRUD operations for all the tables we've structured and created.

> "Spare me", you say.

Of course. Let us first discuss how **sqlx** works.

Being a query builder, it let's you write your SQL in peace. As in:

```rust
let query_result = sqlx::query_as::<Sqlite, Entry>(
  "
  SELECT id, date, sql, prompt, explanation, talk_id
  FROM Entries
  WHERE id = $1;
  ",
)
```

The function query_as lets us set a type for the returned value.
Which will be the structure created earlier. Here is how it looks like:

```rust
#[derive(Clone, FromRow, Debug)]
pub struct Entry {
	id: i32,
	date: String,
	sql: String,
	prompt: String,
	explanation: String,
	talk_id: i32,
}
```

Do you not understand the macros? Well, neither do I.
But I think the syntax will become unpleasant without them.
So ignorance is truly bliss.

I hope you did not think that you can run that query so easily.
We have to add a binding for the $1 value, and execute it, too.
Plus all the error handling that the compiler forces you to do. Lovingly that is.

```rust
pub async fn get_entry(db_pool: Pool<Sqlite>, entry_id: i32)
-> Option<Entry>
{
	let query_result = sqlx::query_as::<Sqlite, Entry>(
	  "
      SELECT id, date, sql, prompt, explanation, talk_id
      FROM Entries
      WHERE id = $1;
      ",
	)
  // bind a value to the $1
	.bind(entry_id)
  // fetch the data (optionally, cause it can be None)
	.fetch_optional(&db_pool)
	.await
	.expect("error :: could not retrieve data from entries table");

	query_result
}
```

And that is basically it, but let me explain two things

The returned **Option\<Entry\>** means that it could return an entry or nothing.

We do not use state here because this is not a handler. I might create more functions to call these.
Too many, I know.

So I <sub>asked ChatGPT and it</sub> wrote 20+ of these.
For dealing with all the operations on the specific tables TalkSQL has.
I had to make corrections a bunch of times, and will have to test these out.
